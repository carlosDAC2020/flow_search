# main.py
import json
from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import JsonOutputParser

# Importamos las cadenas de los agentes
from chains.query_generator import create_query_generator_chain
from chains.research_agent import create_research_chain
from chains.scrutinizer_agent import create_scrutinizer_chain
from chains.extractor_agent import create_full_extraction_pipeline

# Importamos los modelos Pydantic
from schemas.models import QueryList

# ¬°Importamos las NUEVAS funciones secuenciales!
from utils.normalizers import (
    flatten_queries, 
    combine_results, 
    flatten_opportunities,
    scrutinize_sequentially,
    extract_sequentially
)

def main():
    """
    Orquesta el flujo completo de vigilancia tecnol√≥gica.
    """
    # --- Datos de entrada del proyecto (sin cambios) ---
    user_project = {
        "title": "Detecci√≥n de deforestaci√≥n con IA",
        "description": "Sistema de detecci√≥n de deforestaci√≥n en √°reas rurales con inteligencia artificial para ayudar a los campesinos a tomar medidas de acci√≥n y promover la conservaci√≥n.",
        "keywords": ["deforestaci√≥n", "cambio clim√°tico", "inteligencia artificial", "monitoreo ambiental", "sostenibilidad", "agricultura"]
    }
    user_input_str = f"T√≠tulo del proyecto: {user_project['title']}\nDescripci√≥n: {user_project['description']}\nPalabras clave: {', '.join(user_project['keywords'])}"
    
    # --- Construcci√≥n del pipeline completo con l√≥gica SECUENCIAL ---
    print("\nüîó Construyendo el pipeline de vigilancia con pasos secuenciales...")
    
    query_generator = create_query_generator_chain()
    researcher = create_research_chain()
    scrutinizer = create_scrutinizer_chain()
    extractor = create_full_extraction_pipeline()
    
    # Unimos los componentes usando las nuevas funciones
    full_pipeline = (
        query_generator
        | RunnableLambda(lambda x: x['queries'])
        | RunnableLambda(flatten_queries)
        | researcher.map()  # La b√∫squeda s√≠ puede ser en paralelo, es eficiente
        | RunnableLambda(combine_results)
        # 5. Escrutinio SECUENCIAL
        | RunnableLambda(lambda results: scrutinize_sequentially(results, scrutinizer))
        # 6. Extracci√≥n SECUENCIAL
        | RunnableLambda(lambda results: extract_sequentially(results, extractor))
        # 7. Aplanamos la lista final de oportunidades
        | RunnableLambda(flatten_opportunities)
    )

    # --- Ejecuci√≥n del pipeline (sin cambios) ---
    print("\nüöÄ Ejecutando el pipeline completo...")
    
    parser = JsonOutputParser(pydantic_object=QueryList)
    initial_input = {
        "project_details": user_input_str,
        "format_instructions": parser.get_format_instructions()
    }
    
    final_results = full_pipeline.invoke(initial_input)
    
    print("\n‚úÖ Pipeline completado exitosamente.")
    print(f"\nüìÑ Se encontraron {len(final_results)} oportunidades de financiaci√≥n. Mostrando la lista final:\n")
    print(json.dumps(final_results, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()